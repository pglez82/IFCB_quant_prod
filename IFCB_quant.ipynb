{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check that we have everything here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.isdir(\"quantificationlib\"):\n",
    "    print(\"You should have the quantification library in this directory\")\n",
    "    raise StopExecution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Load the data\n",
    "trainpreds = np.genfromtxt('results/trainpred.csv', delimiter=',')\n",
    "traintrue = np.genfromtxt('results/traintrue.csv', delimiter=',')\n",
    "trainprobs = np.genfromtxt('results/trainprobs.csv', delimiter=',')\n",
    "classes=np.genfromtxt('results/classes.csv',dtype='str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit quantification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class CC: Computing predictions for training distribution...done\n",
      "Class AC: Computing predictions for training distribution...done\n",
      "Class AC: Estimating confusion matrix for training distribution...done\n",
      "Class DFy: Computing predictions for training distribution...done\n",
      "Class DFy: Estimating training distribution...done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DFy(distance='HD', distribution_function='PDF', estimator_test=None,\n",
       "    estimator_train=None, n_bins=8, tol=1e-05, verbose=1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path.insert(0, os.path.abspath(\"quantificationlib\"))\n",
    "from quantificationlib import classify_and_count\n",
    "from quantificationlib import distribution_matching\n",
    "\n",
    "quantifierCC = classify_and_count.CC(verbose=1)\n",
    "quantifierAC = classify_and_count.AC(verbose=1)\n",
    "quantifierHDy = distribution_matching.DFy(verbose=1)\n",
    "quantifierCC.fit(None,traintrue,predictions_train=trainpreds)\n",
    "quantifierAC.fit(None,traintrue,predictions_train=trainprobs)\n",
    "quantifierHDy.fit(None,traintrue,predictions_train=trainprobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Receiving the sample to quantify\n",
    "Here I need to create a custom dataset to load the images from a folder without structure (no labels in this case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1967 images \n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from natsort import natsorted\n",
    "\n",
    "class ProductionDataset(Dataset):\n",
    "    def __init__(self, main_dir, transform):\n",
    "        self.main_dir = main_dir\n",
    "        self.transform = transform\n",
    "        all_imgs = os.listdir(main_dir)\n",
    "        self.total_imgs = natsorted(all_imgs)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.total_imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_loc = os.path.join(self.main_dir, self.total_imgs[idx])\n",
    "        image = Image.open(img_loc).convert(\"RGB\")\n",
    "        tensor_image = self.transform(image)\n",
    "        return tensor_image\n",
    "\n",
    "prod_transform = T.Compose([\n",
    "  T.Resize(size=256),\n",
    "  T.CenterCrop(size=224),\n",
    "  T.ToTensor(),\n",
    "  #T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "])\n",
    "\n",
    "#This directory should be the directory with the new images... using validation for simplicity here\n",
    "prod_dset = ProductionDataset(\"production\", transform=prod_transform)\n",
    "prod_loader = DataLoader(prod_dset,batch_size=256,num_workers=4)\n",
    "print(\"Loaded %d images \" % len(prod_dset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding all neccesary functions\n",
    "\n",
    "In this case the make prediction function does not use y (because they are not known). Also the load_network always needs a model.pt file (We have ran finetuning before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as nnf\n",
    "from PIL import Image\n",
    "\n",
    "def load_network():\n",
    "  num_classes=51\n",
    "  model = torchvision.models.resnet34(pretrained=True)\n",
    "  print(\"Adjusting the CNN for %s classes\" % num_classes)\n",
    "  model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "  #Define loss function\n",
    "  loss_fn = nn.CrossEntropyLoss()\n",
    "  model.load_state_dict(torch.load(\"model.pt\"))\n",
    "  model = model.to(device) #Send model to gpu\n",
    "  return model,loss_fn\n",
    "\n",
    "def make_preds(model, loader, device):\n",
    "  \"\"\"\n",
    "  Check the accuracy of the model.\n",
    "  \"\"\"\n",
    "  with torch.no_grad():\n",
    "    # Set the model to eval mode\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    y_probs = []\n",
    "    for x in loader:\n",
    "      x = x.to(device)\n",
    "      # Run the model forward, and compare the argmax score with the ground-truth\n",
    "      # category.\n",
    "      output = model(x)\n",
    "      predicted = output.argmax(1)\n",
    "      prob = nnf.softmax(output, dim=1)\n",
    "      y_probs.extend(prob.cpu().detach().numpy())\n",
    "      y_pred.extend(predicted.cpu().numpy())\n",
    "  return y_pred,y_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify the sample and then quantify it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0\n",
      "Adjusting the CNN for 51 classes\n",
      "Class CC: Computing predictions for testing distribution...done\n",
      "Class CC: Computing prevalences for testing distribution...done\n",
      "Class AC: Computing predictions for testing distribution...done\n",
      "Class AC: Computing prevalences for testing distribution...done\n",
      "Class DFy: Computing predictions for testing distribution...done\n",
      "Class DFy: Estimating testing distribution...Class DFy: Computing prevalences...done\n",
      "                         CC      AC     HDy\n",
      "Asterionellopsis    0.00203 0.00330 0.01321\n",
      "Cerataulina         0.00000 0.00000 0.00000\n",
      "Ceratium            0.00051 0.00176 0.00000\n",
      "Chaetoceros         0.00661 0.00301 0.00630\n",
      "Corethron           0.00153 0.00176 0.00196\n",
      "Coscinodiscus       0.00102 0.00196 0.01200\n",
      "Cylindrotheca       0.00915 0.00988 0.03386\n",
      "DactFragCerataul    0.00051 0.00000 0.00000\n",
      "Dactyliosolen       0.00051 0.00000 0.00000\n",
      "Dictyocha           0.00051 0.00171 0.00000\n",
      "Dinobryon           0.00000 0.00000 0.00000\n",
      "Dinophysis          0.00000 0.00000 0.00000\n",
      "Ditylum             0.00356 0.00426 0.00345\n",
      "Ephemera            0.00000 0.00000 0.00000\n",
      "Eucampia            0.00000 0.00000 0.00000\n",
      "Euglena             0.00000 0.00000 0.00000\n",
      "Gonyaulax           0.00915 0.00917 0.01028\n",
      "Guinardia           0.01118 0.01027 0.01867\n",
      "Guinardia_flaccida  0.00051 0.00168 0.00000\n",
      "Guinardia_striata   0.00051 0.00237 0.00000\n",
      "Gyrodinium          0.00102 0.00164 0.00000\n",
      "Hemiaulus           0.00000 0.00000 0.00000\n",
      "Laboea              0.00000 0.00000 0.00000\n",
      "Lauderia            0.00000 0.00000 0.00000\n",
      "Leptocylindrus      0.08439 0.08733 0.11143\n",
      "Licmophora          0.00000 0.00000 0.00000\n",
      "Myrionecta          0.00051 0.00183 0.00000\n",
      "Odontella           0.00000 0.00000 0.00000\n",
      "Paralia             0.00000 0.00000 0.00000\n",
      "Phaeocystis         0.00000 0.00000 0.00000\n",
      "Pleurosigma         0.00051 0.00160 0.00000\n",
      "Prorocentrum        0.00000 0.00000 0.00000\n",
      "Pseudonitzschia     0.00051 0.00231 0.00000\n",
      "Pyramimonas         0.00000 0.00000 0.00000\n",
      "Rhizosolenia        0.00051 0.00000 0.00000\n",
      "Skeletonema         0.00407 0.00458 0.01120\n",
      "Stephanopyxis       0.00000 0.00000 0.00000\n",
      "Thalassionema       0.00000 0.00000 0.00000\n",
      "Thalassiosira       0.01373 0.01538 0.01045\n",
      "Thalassiosira_dirty 0.00254 0.00413 0.01046\n",
      "bad                 0.00000 0.00000 0.00000\n",
      "ciliate_mix         0.00305 0.00184 0.00191\n",
      "clusterflagellate   0.00000 0.00000 0.00000\n",
      "detritus            0.23742 0.28790 0.18227\n",
      "dino30              0.00203 0.00000 0.00000\n",
      "kiteflagellates     0.00000 0.00000 0.00000\n",
      "mix                 0.59583 0.53877 0.57254\n",
      "mix_elongated       0.00407 0.00000 0.00000\n",
      "na                  0.00153 0.00089 0.00000\n",
      "pennate             0.00051 0.00000 0.00000\n",
      "tintinnid           0.00051 0.00070 0.00000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using %s\"%device)\n",
    "\n",
    "model,_ =  load_network()\n",
    "y_pred,y_probs = make_preds(model, prod_loader, device)\n",
    "y_pred=np.vstack( y_pred )\n",
    "y_probs=np.vstack( y_probs )\n",
    "\n",
    "resultsCC=quantifierCC.predict(None,predictions_test=y_pred)\n",
    "resultsAC=quantifierAC.predict(None,predictions_test=y_pred)\n",
    "resultsHDy=quantifierHDy.predict(None,predictions_test=y_probs)\n",
    "\n",
    "print(pd.DataFrame({'CC':resultsCC,'AC':resultsAC,'HDy':resultsHDy},index=classes))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
