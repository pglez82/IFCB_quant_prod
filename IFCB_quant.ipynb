{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check that we have everything here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.isdir(\"quantificationlib\"):\n",
    "    print(\"You should have the quantification library in this directory\")\n",
    "    raise StopExecution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the quantification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class CC: Computing predictions for training distribution...done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CC(estimator_test=None, verbose=1)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys,os\n",
    "import numpy as np\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(\"quantificationlib\"))\n",
    "from quantificationlib import classify_and_count\n",
    "\n",
    "#Load the data\n",
    "trainpreds = np.genfromtxt('results/trainpred.csv', delimiter=',')\n",
    "traintrue = np.genfromtxt('results/traintrue.csv', delimiter=',')\n",
    "trainprobs = np.genfromtxt('results/trainprobs.csv', delimiter=',')\n",
    "\n",
    "quantifierCC = classify_and_count.CC(verbose=1)\n",
    "quantifierCC.fit(None,traintrue,predictions_train=trainpreds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Receiving the sample to quantify\n",
    "Here I need to create a custom dataset to load the images from a folder without structure (no labels in this case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17.\n",
      " 18. 19. 20. 21. 22. 23. 24. 25. 26. 27. 28. 29. 30. 31. 32. 33. 34. 35.\n",
      " 36. 37. 38. 39. 40. 41. 42. 43. 44. 45. 46. 47. 48. 49. 50.]\n",
      "Loaded 1967 images \n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from natsort import natsorted\n",
    "\n",
    "class ProductionDataset(Dataset):\n",
    "    def __init__(self, main_dir, transform):\n",
    "        self.main_dir = main_dir\n",
    "        self.transform = transform\n",
    "        all_imgs = os.listdir(main_dir)\n",
    "        self.total_imgs = natsorted(all_imgs)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.total_imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_loc = os.path.join(self.main_dir, self.total_imgs[idx])\n",
    "        image = Image.open(img_loc).convert(\"RGB\")\n",
    "        tensor_image = self.transform(image)\n",
    "        return tensor_image\n",
    "\n",
    "prod_transform = T.Compose([\n",
    "  T.Resize(size=256),\n",
    "  T.CenterCrop(size=224),\n",
    "  T.ToTensor(),\n",
    "  #T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "])\n",
    "\n",
    "#This directory should be the directory with the new images... using validation for simplicity here\n",
    "prod_dset = ProductionDataset(\"production\", transform=prod_transform)\n",
    "prod_loader = DataLoader(prod_dset,batch_size=256,num_workers=4)\n",
    "print(\"Loaded %d images \" % len(prod_dset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding all neccesary functions\n",
    "\n",
    "In this case the make prediction function does not use y (because they are not known). Also the load_network always needs a model.pt file (We have ran finetuning before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as nnf\n",
    "from PIL import Image\n",
    "\n",
    "def load_network():\n",
    "  num_classes=51\n",
    "  model = torchvision.models.resnet34(pretrained=True)\n",
    "  print(\"Adjusting the CNN for %s classes\" % num_classes)\n",
    "  model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "  #Define loss function\n",
    "  loss_fn = nn.CrossEntropyLoss()\n",
    "  model.load_state_dict(torch.load(\"model.pt\"))\n",
    "  model = model.to(device) #Send model to gpu\n",
    "  return model,loss_fn\n",
    "\n",
    "def make_preds(model, loader, device):\n",
    "  \"\"\"\n",
    "  Check the accuracy of the model.\n",
    "  \"\"\"\n",
    "  with torch.no_grad():\n",
    "    # Set the model to eval mode\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    y_probs = []\n",
    "    for x in loader:\n",
    "      x = x.to(device)\n",
    "      # Run the model forward, and compare the argmax score with the ground-truth\n",
    "      # category.\n",
    "      output = model(x)\n",
    "      predicted = output.argmax(1)\n",
    "      prob = nnf.softmax(output, dim=1)\n",
    "      y_probs.extend(prob.cpu().detach().numpy())\n",
    "      y_pred.extend(predicted.cpu().numpy())\n",
    "  return y_pred,y_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify the sample and then quantify it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0\n",
      "Adjusting the CNN for 51 classes\n",
      "Class CC: Computing predictions for testing distribution...done\n",
      "Class CC: Computing prevalences for testing distribution...done\n",
      "[2.03355363e-03 0.00000000e+00 5.08388409e-04 6.60904931e-03\n",
      " 1.52516523e-03 1.01677682e-03 9.15099136e-03 5.08388409e-04\n",
      " 5.08388409e-04 5.08388409e-04 0.00000000e+00 0.00000000e+00\n",
      " 3.55871886e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 9.15099136e-03 1.11845450e-02 5.08388409e-04 5.08388409e-04\n",
      " 1.01677682e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 8.43924759e-02 0.00000000e+00 5.08388409e-04 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 5.08388409e-04 0.00000000e+00\n",
      " 5.08388409e-04 0.00000000e+00 5.08388409e-04 4.06710727e-03\n",
      " 0.00000000e+00 0.00000000e+00 1.37264870e-02 2.54194204e-03\n",
      " 0.00000000e+00 3.05033045e-03 0.00000000e+00 2.37417387e-01\n",
      " 2.03355363e-03 0.00000000e+00 5.95831215e-01 4.06710727e-03\n",
      " 1.52516523e-03 5.08388409e-04 5.08388409e-04]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using %s\"%device)\n",
    "\n",
    "model,_ =  load_network()\n",
    "y_pred,y_probs = make_preds(model, prod_loader, device)\n",
    "y_pred=np.vstack( y_pred )\n",
    "print(quantifierCC.predict(None,predictions_test=y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
